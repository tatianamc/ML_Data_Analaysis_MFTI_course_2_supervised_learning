{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import cross_validation, datasets, linear_model, metrics\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генерация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы решаем задачу регрессии, нам очень подойдет функция make_regression. Она позволяет построить соответствующий dataset. В данном случае мы будем строить dataset с двумя признаками. Пускай один из них будет информативным, другой будет избыточным. Также добавим некоторый шум. Еще один параметр, который мы укажем, это параметр coef = True. Он нужен для того, чтобы мы могли с вами посмотреть на уравнение функции, которую мы приближаем. То есть мы попросим метод вернуть нам не только данные и метки, но и также уравнение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, target, coef = datasets.make_regression(n_features = 2, n_informative = 1, n_targets = 1, \n",
    "                                              noise = 5., coef = True, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем отрисовать наш dataset. В данном случае мы не сможем действовать полностью аналогично тому, как мы делали в задаче классификации, потому что у нас в данном случае нет меток классов и мы просто не сможем отрисовать их разным цветом. Мы приближаем некоторую функцию. Тогда мы можем поступить другим образом — мы можем построить некоторую зависимость между нашими признаками и целевой меткой. Например, мы можем отобразить объекты в плоскости «признаки–метки», таким образом мы сможем понять, есть ли какая-то зависимость между значением признаков и значением целевой метки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x110914d68>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109b2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.scatter(list(map(lambda x:x[0], data)), target, color = 'r')\n",
    "pylab.scatter(list(map(lambda x:x[1], data)), target, color = 'b')\n",
    "#для Python 3.5 подставляем list (map(lambda.......))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По этому графику легко проанализировать и понять, какой же из двух признаков является информативным. Вот давайте посмотрим. Нулевой признак отображен точками красного цвета. Мы видим, что в основном с увеличением значения признака у нас растет target. Таким образом, понятно, что зависимость между этим признаком и целевой переменной есть. С другой стороны, давайте посмотрим на синие точки (это второй признак). Мы видим, что, в общем-то, изменение этого признака, например его рост, не всегда означает рост целевой функции. У нас в этом случае есть некоторые случайные изменения, поэтому понятно, что этот признак не настолько информативен. С другой стороны, давайте посмотрим на синие точки (это второй признак). Мы видим, что, в общем-то, изменение этого признака, например его рост, не всегда означает рост целевой функции. У нас в этом случае есть некоторые случайные изменения, поэтому понятно, что этот признак не настолько информативен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(data, target,  \n",
    "                                                                                     test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "еперь давайте построим модель и посмотрим на коэффициенты между этими признаками. Понятно, что мы ожидаем больший коэффициент (я имею в виду абсолютную величину) перед информативным признаком и меньший коэффициент по абсолютной величине перед избыточным признаком. Вот давайте это проанализируем. Для того чтобы построить модель и оценить ее качество, разобьем данные на обучение и тест, и теперь давайте строить модель. Воспользуемся классификатором linear_regression, обучим его на train_data и train_labels и получим наши predictions с помощью метода predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_regressor = linear_model.LinearRegression()\n",
    "linear_regressor.fit(train_data, train_labels)\n",
    "predictions = linear_regressor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  38.36241814  -57.46293828   20.87713077   13.02656201  -11.18242389\n",
      "  -48.28700118   64.70214251  -18.86438755   49.41686419  -22.33224966\n",
      "   22.2276832   -32.92158843 -105.77758163  -71.3715844    10.33267887\n",
      "   29.8208999   -10.27758354  -37.31870104  -22.32195021  -19.36956003\n",
      "   -4.38652971  -18.57607726   41.95683853  -52.37232463  -10.06708677\n",
      "   44.66274342  -16.65927231   13.31981235  -16.79027112  -36.44717565]\n"
     ]
    }
   ],
   "source": [
    "print (test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  41.87878294  -55.41766419   13.43517273   18.68755944  -13.24520106\n",
      "  -56.77091097   68.5643185   -18.93069461   56.03685278  -29.44984904\n",
      "   18.62701015  -34.51555319 -103.29470946  -72.33563455    8.86274742\n",
      "   31.60041345   -7.90384589  -35.54256247  -23.24922863  -32.57101323\n",
      "   -5.09743802  -25.61384455   44.23910522  -41.40762835   -9.83618103\n",
      "   51.07413301  -14.83682009   14.30088312  -15.09407947  -41.6251515 ]\n"
     ]
    }
   ],
   "source": [
    "print( predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь давайте выведем то, как мы эту функцию приблизили на тестовых объектах. Но так как довольно сложно оценить, насколько у нас хорошо получилось, вот давайте для этого введем некоторую метрику. Будем использовать среднее отклонение нашего приближения от исходного значения функции. Посчитаем. Видим, что в среднем мы ошибаемся на 4,2. (у мнея 3.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8120863232262772"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скажем, что будем пользоваться метрикой mean_absolute_error (та же самая метрика, которой мы только что воспользовались) и будем делать кросс-валидацию k-fold на 10 фолдов. Сразу же после этого выпишем среднее и отклонение по нашей метрике. Мы видим, что в среднем наша ошибка равна 4 с отклонением 1. Единственное, что нас здесь должно смутить, это знак «минус» перед средним. Ну, действительно, мы оцениваем метрику «среднее абсолютное отклонение», поэтому она должна быть неотрицательной. А здесь мы видим минус, потому что функция cross_val_score часто используется для подбора параметров алгоритма. В данном случае в качества scoring мы передаем метрику, которая не растет, когда модель становится лучше, а которая уменьшается, когда модель становится лучше. А так как при подборе параметров часто используется максимизация нашей метрики, то нам просто удобно иногда умножить нашу метрику на (−1) и дальше ее точно так же максимизировать. А так как функция cross_val_score понимает, что функция mean_absolute_error растет, когда модель ухудшается, то нам действительно просто умножить эту функцию на (−1). В данном случае мы с вами подбор параметров не делаем, мы ничего не оптимизируем, поэтому, конечно, нам это неудобно. Чтобы от такого избавиться, мы можем создать свой собственный scorer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -4.070071498779697, std: 1.0737104492890202\n"
     ]
    }
   ],
   "source": [
    "linear_scoring = cross_validation.cross_val_score(linear_regressor, data, target, scoring = 'mean_absolute_error', \n",
    "                                                  cv = 10)\n",
    "print ('mean: {}, std: {}'.format(linear_scoring.mean(), linear_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorer = metrics.make_scorer(metrics.mean_absolute_error, greater_is_better = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 4.070071498779697, std: 1.0737104492890202\n"
     ]
    }
   ],
   "source": [
    "linear_scoring = cross_validation.cross_val_score(linear_regressor, data, target, scoring=scorer, \n",
    "                                                  cv = 10)\n",
    "print( 'mean: {}, std: {}'.format(linear_scoring.mean(), linear_scoring.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим на коэффициенты нашей исходной функции. Помните, мы их получили в самом начале, когда генерировали данные. Выведем эти коэффициенты. Ну и видим, что коэффициент перед первым признаком равен 38 (это информативный признак) и перед вторым признаком признаком равен 0 (это избыточный признак). Теперь давайте посмотрим, какие же коэффициенты подобрала наша модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 38.07925837,   0.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим, какие же коэффициенты подобрала наша модель. Ну да, видим, что ответ довольно близок к исходному. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 38.61883503,   0.21821121])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.56991363259908989"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в лекции не указано, что в уравнении обученной модели также участвует свободный член\n",
    "linear_regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 38.08*x1 + 0.00*x2\n"
     ]
    }
   ],
   "source": [
    "print( \"y = {:.2f}*x1 + {:.2f}*x2\".format(coef[0], coef[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 38.62*x1 + 0.22*x2 + -0.57\n"
     ]
    }
   ],
   "source": [
    "print (\"y = {:.2f}*x1 + {:.2f}*x2 + {:.2f}\".format(linear_regressor.coef_[0], \n",
    "                                                  linear_regressor.coef_[1], \n",
    "                                                  linear_regressor.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso_regressor = linear_model.Lasso(random_state = 3)\n",
    "lasso_regressor.fit(train_data, train_labels)\n",
    "lasso_predictions = lasso_regressor.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы рассмотрим лассо-регрессию — регрессию с использованием регуляризации lasso или регуляризации L1. Давайте также построим модель, обучим ее на обучающих данных и и построим наше приближение. Делаем это с помощью функций fit и predict так же, как и раньше. Сразу же оценим качество модели по кросс-валидации. Будем использовать тот же самый scorer, чтобы получить неотрицательное значение метрики. Видим, что, судя по всему, качество стало немножечко хуже. Ну, понятно, что это не значимо, но тем не менее средняя ошибка немножечко больше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 4.154478246666397, std: 1.0170354384993354\n"
     ]
    }
   ],
   "source": [
    "lasso_scoring = cross_validation.cross_val_score(lasso_regressor, data, target, scoring = scorer, cv = 10)\n",
    "print ('mean: {}, std: {}'.format(lasso_scoring.mean(), lasso_scoring.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тличие в том, что в данном случае перед неинформативным признаком мы получили 0. Здесь мы видим результат применения L1-регуляризации. На этом модельном примере очень хорошо видны особенности работы лассо-регуляризации. Мы видим, что у нас как будто бы произошел отбор признаков. Перед избыточным признаком мы получили вес 0. Таким образом, теперь вы знаете, что если в вашей задаче много избыточных признаков и вы хотите заняться отбором признаков, то есть вы хотите получить перед ними не просто маленькие веса, а действительно получить нули и отфильтровать такие признаки, то лассо-регуляризация очень хорошо подходит для этой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 37.87995654   0.        ]\n"
     ]
    }
   ],
   "source": [
    "print (lasso_regressor.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"y = {:.2f}*x1 + {:.2f}*x2\".format(coef[0], coef[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"y = {:.2f}*x1 + {:.2f}*x2\".format(lasso_regressor.coef_[0], lasso_regressor.coef_[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
