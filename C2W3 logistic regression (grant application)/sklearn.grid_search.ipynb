{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "документация: http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.1\n",
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation, datasets, grid_search, linear_model, metrics\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(iris.data, iris.target, \n",
    "                                                                                     test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = linear_model.SGDClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация сетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_iter', 'penalty', 'l1_ratio', 'fit_intercept', 'warm_start', 'class_weight', 'random_state', 'average', 'shuffle', 'power_t', 'alpha', 'verbose', 'n_jobs', 'epsilon', 'eta0', 'loss', 'learning_rate'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params().keys()# степени свободы, какие параметры мы можем подобрать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    'loss' : ['hinge', 'log', 'squared_hinge', 'squared_loss'],\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'n_iter' : range(5,10),\n",
    "    'alpha' : np.linspace(0.0001, 0.001, num = 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте будем подбирать только несколько. С одной стороны, можно выбрать вид функции потерь, будем рассматривать hinge, log, squared_hinge и squared_loss. Также давайте выберем вид регуляризации — выберем между l1 и l2. Также можем подобрать количество итераций — давайте подбирать от 5 до 10, по умолчанию у нас 5 итераций. И выберем коэффициент alpha — это множитель перед регуляризацией. По умолчанию у нас доступно значение 0,0001. Ну, вот давайте создадим отрезок от 0,0001 до 0,001, бросим на него равномерно пять точек и будем использовать их в качестве весов. Это можно сделать с помощью метода linspace. \n",
    "В данном случае в качестве сетки мы будем использовать словарь, у которого ключ — это название параметра, который мы подбираем. Видите, что эти названия совпадают с названиями из get_params. А в качестве значения идет набор значений, которые мы хотим проверить. Таким образом, если мы построим декартово произведение на этих параметрах, то мы получим точки со всеми возможными наборами параметров. Собственно, это нам и хочется получить. Мы хотим в каждой из этих точек измерить качество классификации, далее сравнить, посмотреть, где качество максимальное, и сказать, что вот это есть оптимальные параметры. Это такой метод полного перебора на множестве параметров, и, в общем-то, он и называется поиском по сетке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = cross_validation.StratifiedShuffleSplit(train_labels, n_iter = 10, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "так, давайте создадим стратегию кросс-валидации, с помощью которой мы будем оценивать качество. В данном случае я использую ShuffleSplit, буду делать 10 итераций, и в тестовую выборку будет идти 20 % данных. И теперь можно перейти непосредственно как бы к подбору параметров. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grid_cv = grid_search.GridSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print grid_cv.best_score_\n",
    "print grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_cv.grid_scores_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomized_grid_cv = grid_search.RandomizedSearchCV(classifier, parameters_grid, scoring = 'accuracy', cv = cv, n_iter = 20, \n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "randomized_grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print randomized_grid_cv.best_score_\n",
    "print randomized_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
